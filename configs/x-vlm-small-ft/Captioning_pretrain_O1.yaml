train_file: [
    "hdfs://path/to/coco",  # a directory, which contains for example 64 files. Each file contains multiple lines, and each line is a json object(dict).
    "hdfs://path/to/vg",
    "hdfs://path/to/sbu",
    "hdfs://path/to/cc3m",
               ]

train_dataset_size: 5114489 # for IterableDataset
images: {image_key: "binary",
         is_image_rpath: False, # read path or base64 encoding
         caption_key: "desc",
         tokenized: False,  # whether texts have been tokenized
         batch_size: 128,
         num_workers: 4,  # better -> the number of training files % (world_size * num_workers) == 0
}

## Vision Encoder
use_clip_vit: True
vision_config: 'configs/config_clipvit_small.json'
image_res: 224
patch_size: 16

## Text Encoder (& Cross Encoder)
text_encoder: 'data/bert-base-uncased'
text_num_hidden_layers: 6  # 3 for text encoder, 3 for cross encoder


## Training
embed_dim: 256

max_words: 40
max_tokens: 40
#### these will not be activated
mask_whole_word: True
mask_prob: 0.25
max_masks: 8
skipgram_prb: 0.2
skipgram_size: 3
####


## Other Settings
optimizer: {opt: adamW, lr: 3e-5, weight_decay: 0.01, lr_mult: 2}
schedular: {sched: linear, lr: 3e-5, epochs: 2, num_warmup_steps: 0.1}
accelerator: {SYNCBN: false, FP16_OPT_LEVEL: O1, FP16_LOSS_SCALE: dynamic, RNG_SEED: 42, GRAD_ACCUMULATE_STEPS: 1, CLIP_GRAD_NORM: 1.0}
